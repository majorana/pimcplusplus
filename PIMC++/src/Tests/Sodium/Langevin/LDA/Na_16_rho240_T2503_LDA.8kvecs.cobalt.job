#!/bin/csh
#
#  Sample Batch Script for a SGI Altix MPI job
#
#  Submit this script using the command: qsub mpi.pbs
#
#  Use the "qstat" command to check the status of a job.
#
# The following are embedded QSUB options. The syntax is #PBS (the # does
# _not_ denote that the lines are commented out so do not remove).
#
# 
# Set maximum wallclock time to 30 minutes (hh:mm:ss)
#PBS -l walltime=18:00:00

# Set memory limit to 500 Mbytes
#PBS -l mem=32gb

# Request 4 processors
#PBS -l ncpus=32

# Queue name (see info about other queues in web documentation)
#PBS -q standard
#
# Export all my environment variables to the job
#PBS -V
#
# Charge job to project abc (recommended for users with multiple projects)
# [If project is invalid, a valid project will be automatically selected]
# 
# Job name (default = name of script file)
#
# Filename for standard output (default = <job_name>.o<job_id>)
#
# Filename for standard error (default = <job_name>.e<job_id>)
# 
# Send mail when the job begins and ends (optional)
#PBS -m be
#------------------------------
# End of embedded QSUB options

#set echo               # echo commands before execution; use for debugging

# tar up output files and save them on UniTree after the job is completed
# (We assume that subdirectory "dir2" has already been created.)
#saveafterjob "cd dir2,tar cf output.tar *.output"

# Get files su3_rmd-pt and input.8.10 from directory in UniTree

# Run the MPI program on all nodes/processors requested by the job
# (program reads from input.8.10 and writes to output.8.10)
cd ~/svnwork/PIMC++/src/Tests/Sodium/Langevin
mpirun -np $NCPUS pimc++ Na_16_rho240_T2503_LDA.8kvecs.in

